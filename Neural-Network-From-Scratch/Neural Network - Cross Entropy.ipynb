{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Multi Layer Perceptron From Scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Activation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def step_func(x):\n",
    "    return 1 if x >= 0 else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1 + math.exp(-x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Output function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def neuron_output(weights, x):\n",
    "    return sigmoid(np.dot(weights, x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feed-Forward"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It receives a neural network, represented as a list of lists of weights lists, and returns the output from the input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feed_forward(neural_network, input_vec):\n",
    "    outputs = []\n",
    "    \n",
    "    # Process one layer at a time\n",
    "    for layer in neural_network:\n",
    "        input_with_bias = list(input_vec) + [1]\n",
    "        output = [neuron_output(neuron, input_with_bias) for neuron in layer]\n",
    "        outputs.append(output)\n",
    "        \n",
    "        input_vec = output\n",
    "    \n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feed-Forward network example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural network simulating XOR port"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The weights chosen for the XOR network were chosen precisely to implement the or-exclusive function. This function is not linear, so only one Perceptron is not able to adjust to this function.\n",
    "The weights of the neurons are chosen so that the first layer is composed of an AND neuron and another OR and the second layer is composed of a neuron \"second entrance and not the first one\".\n",
    "\n",
    "- Weights AND: [k, k, -3k]\n",
    "- Weights OR: [k, k, -0.5k]\n",
    "- Weights \"second entrance and not the first one\": [-k, k, -0.5k]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"xor_img.png\" alt=\"Drawing\" style=\"width: 550px;\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 [9.38314668300676e-14]\n",
      "0 1 [0.9999999999999059]\n",
      "1 0 [0.9999999999999059]\n",
      "1 1 [9.383146683006828e-14]\n"
     ]
    }
   ],
   "source": [
    "xor_network = [# hidden layer\n",
    "                [[20, 20, -30], #AND\n",
    "                 [20, 20, -10]], # OR\n",
    "               # output layer\n",
    "                 [[-60, 60, -30]]] # second entrance and not the first one\n",
    "\n",
    "for x in [0, 1]:\n",
    "    for y in [0, 1]:\n",
    "        print(x, y, feed_forward(xor_network, [x, y])[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Backpropagation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Backpropagation Step by Step:\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Run the feed_forward for an input and save the outputs of each neuron\n",
    "- Calculate the error for each neuron (target - output)\n",
    "- Calculate the gradient for this error as a function of the weights of the neural network\n",
    "- Adjust the weights in the direction that the error decreases\n",
    "- Propagate output errors to hidden layers\n",
    "- Calculate the gradients of these errors and adjust the weights of all hidden layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backpropagate(network, input_vec, targets):\n",
    "    \n",
    "    # feed_forward for the input\n",
    "    hidden_outputs, outputs = feed_forward(network, input_vec)\n",
    "    \n",
    "    # Calculates the error for the output\n",
    "    output_deltas = [output * (1 - output) * (output - target) for output, target in zip(outputs, targets)]\n",
    "    \n",
    "    # Adjusts the weights for the output layer, one neuron at a time\n",
    "    for i, output_neuron in enumerate(network[-1]):\n",
    "        # -1 to focus on the last layer (of output)\n",
    "        for j, hidden_output in enumerate(hidden_outputs + [1]):\n",
    "            # adjusts the j-th weight of this neuron\n",
    "            output_neuron[j] -= output_deltas[i] * hidden_output\n",
    "    \n",
    "    # Calculates the error for the hidden layer\n",
    "    hidden_deltas = [hidden_output * (1 - hidden_output) * np.dot(output_deltas, [n[i] for n in output_layer])\n",
    "                    for i, hidden_output in enumerate(hidden_outputs)]\n",
    "    \n",
    "    # Adjusts the weights for the hidden layer, one neuron at a time\n",
    "    for i, hidden_neuron in enumerate(network[0]):\n",
    "        for j, input in enumerate(input_vec + [1]):\n",
    "            hidden_neuron[j] -= hidden_deltas[i] * input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network vs Captcha"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's train a neural network to try to defeat a simple captcha. Each captcha will be interpreted as a 5x5 matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "zero = [1, 1, 1, 1, 1,\n",
    "        1, 0, 0, 0, 1,\n",
    "        1, 0, 0, 0, 1,\n",
    "        1, 0, 0, 0, 1,\n",
    "        1, 1, 1, 1, 1]\n",
    "one = [0, 0, 1, 0, 0,\n",
    "       0, 0, 1, 0, 0,\n",
    "       0, 0, 1, 0, 0,\n",
    "       0, 0, 1, 0, 0,\n",
    "       0, 0, 1, 0, 0]\n",
    "two = [1, 1, 1, 1, 1,\n",
    "       0, 0, 0, 0, 1,\n",
    "       1, 1, 1, 1, 1,\n",
    "       1, 0, 0, 0, 0,\n",
    "       1, 1, 1, 1, 1]\n",
    "three = [1, 1, 1, 1, 1,\n",
    "         0, 0, 0, 0, 1,\n",
    "         1, 1, 1, 1, 1,\n",
    "         0, 0, 0, 0, 1,\n",
    "         1, 1, 1, 1, 1]\n",
    "four = [1, 0, 0, 0, 1,\n",
    "        1, 0, 0, 0, 1,\n",
    "        1, 1, 1, 1, 1,\n",
    "        0, 0, 0, 0, 1,\n",
    "        0, 0, 0, 0, 1]\n",
    "five = [1, 1, 1, 1, 1,\n",
    "       1, 0, 0, 0, 0,\n",
    "       1, 1, 1, 1, 1,\n",
    "       0, 0, 0, 0, 1,\n",
    "       1, 1, 1, 1, 1]\n",
    "six = [1, 1 ,1, 1 ,1,\n",
    "       1, 0, 0, 0, 0,\n",
    "       1, 1, 1, 1, 1,\n",
    "       1, 0, 0, 0, 1,\n",
    "       1, 1, 1, 1, 1]\n",
    "seven = [1, 1, 1, 1, 1,\n",
    "         0, 0, 0, 0, 1,\n",
    "         0, 0, 0, 0, 1,\n",
    "         0, 0, 0, 0, 1,\n",
    "         0, 0, 0, 0, 1]\n",
    "eight = [1, 1, 1, 1, 1,\n",
    "         1, 0, 0, 0, 1,\n",
    "         1, 1, 1, 1, 1,\n",
    "         1, 0, 0, 0, 1,\n",
    "         1, 1, 1, 1, 1]\n",
    "nine = [1, 1, 1, 1, 1,\n",
    "        1, 0, 0, 0, 1,\n",
    "        1, 1, 1, 1, 1,\n",
    "        0, 0, 0, 0, 1,\n",
    "        1, 1, 1, 1, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we concatenate each number in just one list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 25)\n"
     ]
    }
   ],
   "source": [
    "inputs = [zero, one, two, three, four, five, six, seven, eight, nine]\n",
    "print(np.array(inputs).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the targets, we can create a diagonal matrix 10x10. This is One-Hot encoded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 10)\n"
     ]
    }
   ],
   "source": [
    "targets = [[1 if i == j else 0 for i in range(10)] for j in range(10)]\n",
    "print(np.array(targets).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we build the Neural Network. The input size is 25 (5x5), 5 hidden neurons are suficiente for this task, and 10 neurons for the last layer, since there are 10 classes.\n",
    "\n",
    "All the initial weights are initialized as random."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(42)\n",
    "input_size = 25\n",
    "num_hidden = 5\n",
    "num_class = 10\n",
    "\n",
    "hidden_layer = [[random.random() for _ in range(input_size + 1)]\n",
    "               for _ in range(num_hidden)]\n",
    "\n",
    "output_layer = [[random.random() for _ in range(num_hidden + 1)]\n",
    "               for _ in range(num_class)]\n",
    "\n",
    "network = [hidden_layer, output_layer]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The train function is pretty strait forward. Just executing backpropagation for some epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(network, epochs, inputs, targets):\n",
    "    \n",
    "    for _ in range(epochs):\n",
    "        for input_vec, target_vec in zip(inputs, targets):\n",
    "            backpropagate(network, input_vec, target_vec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10000 Epochs are more then enough, 14seconds on my computer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 12.5 s, sys: 27.9 ms, total: 12.5 s\n",
      "Wall time: 12.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train(network, 10000, inputs, targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The prediction will be the output of the last layer. The argmax function will select the largest probability on that layer for the prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(network, x):\n",
    "    return np.argmax(feed_forward(network, x)[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing the Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's test the network trying to classify data that is not in the training set. For this, we will use numbers drawn in a slightly different way."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"examples.png\" alt=\"Drawing\" style=\"width: 350;\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Testing with a different 3 \n",
    "predict(network, [0, 1, 1, 1, 1,\n",
    "                  0, 0, 0, 1, 1,\n",
    "                  0, 1, 1, 1, 1,\n",
    "                  0, 0, 0, 1, 1,\n",
    "                  0, 1 ,1, 1 ,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Testing with a different 7 \n",
    "predict(network, [1, 1, 1, 1, 1,\n",
    "                  0, 0, 0, 1, 0,\n",
    "                  0, 0, 1, 0, 0,\n",
    "                  0, 1, 0, 0, 0,\n",
    "                  1, 0 ,0, 0 ,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Testing with a different 8 \n",
    "predict(network, [0, 1, 1, 1, 0,\n",
    "                  1, 0, 0, 0, 1,\n",
    "                  1, 1, 1, 1, 1,\n",
    "                  1, 0, 0, 0, 1,\n",
    "                  0, 1 ,1, 1 ,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trying to visualize what the neural network does"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can easely check how as the weights distributed. By plotting them in a matrix, the large weights will be blacker and the lower ones will be whiter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_weights(weights):\n",
    "    abs_weights = list(map(abs, weights))\n",
    "    \n",
    "    # transform the weights in a 5x5 grid\n",
    "    grid = [abs_weights[row:(row+5)] for row in range(0,25,5)] \n",
    "\n",
    "    ax = plt.gca() #\n",
    "\n",
    "    ax.imshow(grid,\n",
    "              cmap='binary', # uses black and white\n",
    "              interpolation='none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_weights(network[0][0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:dl]",
   "language": "python",
   "name": "conda-env-dl-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
